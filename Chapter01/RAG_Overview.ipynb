{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqpsYn49QWSR"
      },
      "source": [
        "#Introducing Naive, Advanced, and Modular RAG\n",
        "\n",
        "Copyright 2024, Denis Rothman\n",
        "\n",
        "This notebook introduces Naïve, Advanced, and Modular RAG through basic educational examples.\n",
        "\n",
        "The Naïve, Advanced and modular RAG techniques offer flexibility in selecting retrieval strategies, allowing adaptation to various tasks and data characteristics.\n",
        "\n",
        "**Summary**\n",
        "\n",
        "**Part 1: Foundations and Basic Implementation**\n",
        "\n",
        "1.Environment setup for OpenAI API integration  \n",
        "2.Generator function using GPT models    \n",
        "3.Dataetup with a list of documents (db_records)  \n",
        "4.Query(user request)  \n",
        "\n",
        "**Part 2: Advanced Techniques and Evaluation**\n",
        "\n",
        "1.Retrieval metrics  \n",
        "2.Naive RAG  \n",
        "3.Advanced RAG  \n",
        "4.Modular RAG Retriever  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ICSQQ0ipxlR"
      },
      "source": [
        "# Part 1: Foundations and Basic Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o01-IM8bTc5f"
      },
      "source": [
        "# 1.The Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VCfbN0YwHbE",
        "outputId": "e8d504fe-fa2c-4935-9b26-88900ad35a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.107.2\n",
            "  Downloading openai-1.107.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.2) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.2) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.2) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.2) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.2) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==1.107.2) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.2) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai==1.107.2) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.107.2) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.107.2) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.107.2) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.2) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.2) (0.4.2)\n",
            "Downloading openai-1.107.2-py3-none-any.whl (946 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/946.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m942.1/946.9 kB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m946.9/946.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.12.0\n",
            "    Uninstalling openai-2.12.0:\n",
            "      Successfully uninstalled openai-2.12.0\n",
            "Successfully installed openai-1.107.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.107.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myXJn33zbqTR",
        "outputId": "3ef1f36b-8d4c-477b-c0aa-ecd3f3873707",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#API Key\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Oefvqp21Ba07",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#f = open(\"drive/MyDrive/api_key.txt\", \"r\")\n",
        "#API_KEY=f.readline().strip()\n",
        "API_KEY=\"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\"\n",
        "#f.close()\n",
        "\n",
        "#The OpenAI Key\n",
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuZ7jr4Rs36U"
      },
      "source": [
        "# 2.The Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "qwCNTW9fs36U"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "gptmodel=\"openai/gpt-4o\"\n",
        "\n",
        "def call_llm_with_full_text(itext):\n",
        "\n",
        "     # Join all lines to form a single string\n",
        "    # text_input = '\\n'.join(itext)\n",
        "    text_input = itext\n",
        "    prompt = f\"Please elaborate on the following content:\\n{text_input}\"\n",
        "    print(prompt)\n",
        "\n",
        "    try:\n",
        "      response = client.chat.completions.create(\n",
        "         model=gptmodel,\n",
        "         messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert Natural Language Processing exercise expert\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"1.You can explain read the input and answer in detail\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "         ],\n",
        "         temperature=0.1  # Add the temperature parameter here and other parameters you need\n",
        "        )\n",
        "      return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVKe9VF0HIHJ"
      },
      "source": [
        "## Formatted response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "oG8I2Kb2HFhL"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def print_formatted_response(response):\n",
        "    # Define the width for wrapping the text\n",
        "    wrapper = textwrap.TextWrapper(width=80)  # Set to 80 columns wide, but adjust as needed\n",
        "    wrapped_text = wrapper.fill(text=response)\n",
        "\n",
        "    # Print the formatted response with a header and footer\n",
        "    print(\"Response:\")\n",
        "    print(\"---------------\")\n",
        "    print(wrapped_text)\n",
        "    print(\"---------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv1ExPiZdJRL"
      },
      "source": [
        " # 3.The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "45CFxG4Fgcju"
      },
      "outputs": [],
      "source": [
        "db_records = [\n",
        "  \"Генерация с расширенным поиском (Retrieval Augmented Generation, RAG) представляет собой сложный гибридный подход в области искусственного интеллекта, особенно в сфере обработки естественного языка (NLP).\",\n",
        "  \"Она инновационно сочетает возможности языковых моделей на основе нейронных сетей с системами поиска для повышения точности, информативности и контекстной релевантности генерации текста.\",\n",
        "  \"Эта методология использует сильные стороны как генеративных, так и поисковых архитектур для решения сложных задач, требующих не только лингвистической беглости, но и фактической корректности и глубины знаний.\",\n",
        "  \"В основе генерации с расширенным поиском (RAG) лежит генеративная модель, как правило, нейронная сеть на основе трансформеров, подобная тем, которые используются в таких моделях, как GPT (Generative Pre-trained Transformer) или BERT (Bidirectional Encoder Representations from Transformers).\",\n",
        "  \"Этот компонент отвечает за создание связных и контекстно-релевантных языковых результатов на основе сочетания входных подсказок и дополнительной информации, полученной системой поиска.\",\n",
        "  \"Дополняет языковую модель система поиска, которая обычно строится на основе базы данных документов или корпуса текстов.\",\n",
        "  \"Эта система использует методы информационного поиска для поиска и извлечения документов, релевантных входному запросу или подсказке.\",\n",
        "  \"Механизм определения релевантности может варьироваться от простого сопоставления ключевых слов до более сложных алгоритмов семантического поиска, которые интерпретируют смысл запроса для поиска наилучших совпадений.\",\n",
        "  \"Этот компонент объединяет выходные данные языковой модели и системы поиска.\",\n",
        "  \"Он эффективно синтезирует необработанные данные, полученные системой поиска, в генеративный процесс языковой модели.\",\n",
        "  \"Интегратор обеспечивает бесшовное включение информации из системы поиска в конечный текстовый вывод, повышая способность модели генерировать ответы, которые не только беглы и грамматически корректны, но и богаты фактическими деталями и контекстно-специфическими нюансами.\",\n",
        "  \"Когда получен запрос или подсказка, система сначала обрабатывает его, чтобы понять требование или контекст.\",\n",
        "  \"На основе обработанного запроса система поиска осуществляет поиск в своей базе данных для нахождения релевантных документов или фрагментов информации.\",\n",
        "  \"Этот поиск осуществляется на основе сходства содержимого документов с запросом, которое может быть определено с помощью различных методов, таких как векторные представления или меры семантического сходства.\",\n",
        "  \"Полученные документы затем передаются в языковую модель.\",\n",
        "  \"В некоторых реализациях эта интеграция происходит на уровне токенов, где модель может динамически получать доступ к определенным фрагментам информации из полученных текстов и включать их в процесс генерации каждой части ответа.\",\n",
        "  \"Языковая модель, теперь дополненная прямым доступом к полученной информации, генерирует ответ.\",\n",
        "  \"Этот ответ зависит не только от обучения модели, но и от конкретных фактов и деталей, содержащихся в полученных документах, что делает его более персонализированным и точным.\",\n",
        "  \"Благодаря прямому включению информации из внешних источников, модели генерации с расширенным поиском (RAG) могут создавать ответы, которые являются более фактическими и релевантными заданному запросу\",\n",
        "  \"Это особенно полезно в таких областях, как медицинские консультации, техническая поддержка и другие сферы, где точность и актуальные знания имеют решающее значение.\",\n",
        "  \"Системы дополненной генерации поиска (RAG) могут динамически адаптироваться к новой информации, поскольку они извлекают данные из своих баз данных в режиме реального времени.\",\n",
        "  \"Это позволяет им оставаться в курсе последних знаний и тенденций без необходимости частого переобучения.\",\n",
        "  \"Благодаря доступу к широкому спектру документов, системы дополненной генерации поиска (RAG) могут предоставлять подробные и тонкие ответы, которые автономная языковая модель может быть не в состоянии сгенерировать, основываясь исключительно на своих предварительно обученных знаниях.\",\n",
        "  \"Хотя дополненная генерация поиска (RAG) предлагает существенные преимущества, она также сопряжена со своими проблемами.\",\n",
        "  \"К ним относятся сложность интеграции систем поиска и генерации, вычислительные затраты, связанные с поиском данных в режиме реального времени, и необходимость поддержания большой, актуальной и высококачественной базы данных доступные для поиска тексты.\",\n",
        "  \"Кроме того, обеспечение релевантности и точности извлекаемой информации остается серьезной проблемой, как и управление потенциальной возможностью внесения искажений или ошибок из внешних источников.\",\n",
        "  \"В заключение, генерация с дополненной реальностью (Retrieval Augmented Generation, RAG) представляет собой значительный шаг вперед в области искусственного интеллекта, объединяя лучшие достижения технологий поиска и генеративных технологий для создания систем, которые не только понимают и генерируют естественный язык, но и глубоко понимают и используют огромные объемы информации, доступной в текстовой форме.\",\n",
        "  \"Векторное хранилище RAG — это база данных или набор данных.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIQ7NK92g7EC",
        "outputId": "a266a3ce-3712-4031-c604-edcd9ec04fe7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация с расширенным поиском (Retrieval Augmented Generation, RAG)\n",
            "представляет собой сложный гибридный подход в области искусственного интеллекта,\n",
            "особенно в сфере обработки естественного языка (NLP). Она инновационно сочетает\n",
            "возможности языковых моделей на основе нейронных сетей с системами поиска для\n",
            "повышения точности, информативности и контекстной релевантности генерации\n",
            "текста. Эта методология использует сильные стороны как генеративных, так и\n",
            "поисковых архитектур для решения сложных задач, требующих не только\n",
            "лингвистической беглости, но и фактической корректности и глубины знаний. В\n",
            "основе генерации с расширенным поиском (RAG) лежит генеративная модель, как\n",
            "правило, нейронная сеть на основе трансформеров, подобная тем, которые\n",
            "используются в таких моделях, как GPT (Generative Pre-trained Transformer) или\n",
            "BERT (Bidirectional Encoder Representations from Transformers). Этот компонент\n",
            "отвечает за создание связных и контекстно-релевантных языковых результатов на\n",
            "основе сочетания входных подсказок и дополнительной информации, полученной\n",
            "системой поиска. Дополняет языковую модель система поиска, которая обычно\n",
            "строится на основе базы данных документов или корпуса текстов. Эта система\n",
            "использует методы информационного поиска для поиска и извлечения документов,\n",
            "релевантных входному запросу или подсказке. Механизм определения релевантности\n",
            "может варьироваться от простого сопоставления ключевых слов до более сложных\n",
            "алгоритмов семантического поиска, которые интерпретируют смысл запроса для\n",
            "поиска наилучших совпадений. Этот компонент объединяет выходные данные языковой\n",
            "модели и системы поиска. Он эффективно синтезирует необработанные данные,\n",
            "полученные системой поиска, в генеративный процесс языковой модели. Интегратор\n",
            "обеспечивает бесшовное включение информации из системы поиска в конечный\n",
            "текстовый вывод, повышая способность модели генерировать ответы, которые не\n",
            "только беглы и грамматически корректны, но и богаты фактическими деталями и\n",
            "контекстно-специфическими нюансами. Когда получен запрос или подсказка, система\n",
            "сначала обрабатывает его, чтобы понять требование или контекст. На основе\n",
            "обработанного запроса система поиска осуществляет поиск в своей базе данных для\n",
            "нахождения релевантных документов или фрагментов информации. Этот поиск\n",
            "осуществляется на основе сходства содержимого документов с запросом, которое\n",
            "может быть определено с помощью различных методов, таких как векторные\n",
            "представления или меры семантического сходства. Полученные документы затем\n",
            "передаются в языковую модель. В некоторых реализациях эта интеграция происходит\n",
            "на уровне токенов, где модель может динамически получать доступ к определенным\n",
            "фрагментам информации из полученных текстов и включать их в процесс генерации\n",
            "каждой части ответа. Языковая модель, теперь дополненная прямым доступом к\n",
            "полученной информации, генерирует ответ. Этот ответ зависит не только от\n",
            "обучения модели, но и от конкретных фактов и деталей, содержащихся в полученных\n",
            "документах, что делает его более персонализированным и точным. Благодаря прямому\n",
            "включению информации из внешних источников, модели генерации с расширенным\n",
            "поиском (RAG) могут создавать ответы, которые являются более фактическими и\n",
            "релевантными заданному запросу Это особенно полезно в таких областях, как\n",
            "медицинские консультации, техническая поддержка и другие сферы, где точность и\n",
            "актуальные знания имеют решающее значение. Системы дополненной генерации поиска\n",
            "(RAG) могут динамически адаптироваться к новой информации, поскольку они\n",
            "извлекают данные из своих баз данных в режиме реального времени. Это позволяет\n",
            "им оставаться в курсе последних знаний и тенденций без необходимости частого\n",
            "переобучения. Благодаря доступу к широкому спектру документов, системы\n",
            "дополненной генерации поиска (RAG) могут предоставлять подробные и тонкие\n",
            "ответы, которые автономная языковая модель может быть не в состоянии\n",
            "сгенерировать, основываясь исключительно на своих предварительно обученных\n",
            "знаниях. Хотя дополненная генерация поиска (RAG) предлагает существенные\n",
            "преимущества, она также сопряжена со своими проблемами. К ним относятся\n",
            "сложность интеграции систем поиска и генерации, вычислительные затраты,\n",
            "связанные с поиском данных в режиме реального времени, и необходимость\n",
            "поддержания большой, актуальной и высококачественной базы данных доступные для\n",
            "поиска тексты. Кроме того, обеспечение релевантности и точности извлекаемой\n",
            "информации остается серьезной проблемой, как и управление потенциальной\n",
            "возможностью внесения искажений или ошибок из внешних источников. В заключение,\n",
            "генерация с дополненной реальностью (Retrieval Augmented Generation, RAG)\n",
            "представляет собой значительный шаг вперед в области искусственного интеллекта,\n",
            "объединяя лучшие достижения технологий поиска и генеративных технологий для\n",
            "создания систем, которые не только понимают и генерируют естественный язык, но и\n",
            "глубоко понимают и используют огромные объемы информации, доступной в текстовой\n",
            "форме. Векторное хранилище RAG — это база данных или набор данных.\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "paragraph = ' '.join(db_records)\n",
        "wrapped_text = textwrap.fill(paragraph, width=80)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL7cHuuLhQ5w"
      },
      "source": [
        "# 4.The Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "qARk6gtohSXW"
      },
      "outputs": [],
      "source": [
        "query = \"define a rag store\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iITo3QIF7yeK"
      },
      "source": [
        "Generation without augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXBILWI47yeM",
        "outputId": "3304e617-7715-47d6-9a9f-a4aab1287904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please elaborate on the following content:\n",
            "define a rag store\n",
            "Response:\n",
            "---------------\n",
            "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-\n",
            "or-v1*************************************************************b8cb. You can\n",
            "find your API key at https://platform.openai.com/account/api-keys.', 'type':\n",
            "'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status':\n",
            "401}\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(query)\n",
        "print_formatted_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11HLkKQMqaDt"
      },
      "source": [
        "# Part 2: Advanced Techniques and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMGuZg1WiaUE"
      },
      "source": [
        "# 1.Retrieval Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHN6s7wZirQL"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GLECrTQirQN"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        use_idf=True,\n",
        "        norm='l2',\n",
        "        ngram_range=(1, 2),  # Use unigrams and bigrams\n",
        "        sublinear_tf=True,   # Apply sublinear TF scaling\n",
        "        analyzer='word'      # You could also experiment with 'char' or 'char_wb' for character-level features\n",
        "    )\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
        "    return similarity[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTJOi-jrjI5A"
      },
      "source": [
        "## Enhanced Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnmPG9UWjJXD",
        "outputId": "b7a8db4c-9b16-4a17-cc7f-679d67983912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return synonyms\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    lemmatized_words = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        lemmatized_words.append(token.lemma_)\n",
        "    return lemmatized_words\n",
        "\n",
        "def expand_with_synonyms(words):\n",
        "    expanded_words = words.copy()\n",
        "    for word in words:\n",
        "        expanded_words.extend(get_synonyms(word))\n",
        "    return expanded_words\n",
        "\n",
        "def calculate_enhanced_similarity(text1, text2):\n",
        "    # Preprocess and tokenize texts\n",
        "    words1 = preprocess_text(text1)\n",
        "    words2 = preprocess_text(text2)\n",
        "\n",
        "    # Expand with synonyms\n",
        "    words1_expanded = expand_with_synonyms(words1)\n",
        "    words2_expanded = expand_with_synonyms(words2)\n",
        "\n",
        "    # Count word frequencies\n",
        "    freq1 = Counter(words1_expanded)\n",
        "    freq2 = Counter(words2_expanded)\n",
        "\n",
        "    # Create a set of all unique words\n",
        "    unique_words = set(freq1.keys()).union(set(freq2.keys()))\n",
        "\n",
        "    # Create frequency vectors\n",
        "    vector1 = [freq1[word] for word in unique_words]\n",
        "    vector2 = [freq2[word] for word in unique_words]\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    vector1 = np.array(vector1)\n",
        "    vector2 = np.array(vector2)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "\n",
        "    return cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFqh9rr81SUn"
      },
      "source": [
        "# 2.Naive RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu8vteKmS_qO"
      },
      "source": [
        "## Keyword search and matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY1JU0Ush_l4",
        "outputId": "cd9426f3-43d3-40a7-acc6-f63b2d6bb230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Keyword Score: 3\n",
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def find_best_match_keyword_search(query, db_records):\n",
        "    best_score = 0\n",
        "    best_record = None\n",
        "\n",
        "    # Split the query into individual keywords\n",
        "    query_keywords = set(query.lower().split())\n",
        "\n",
        "    # Iterate through each record in db_records\n",
        "    for record in db_records:\n",
        "        # Split the record into keywords\n",
        "        record_keywords = set(record.lower().split())\n",
        "\n",
        "        # Calculate the number of common keywords\n",
        "        common_keywords = query_keywords.intersection(record_keywords)\n",
        "        current_score = len(common_keywords)\n",
        "\n",
        "        # Update the best score and record if the current score is higher\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_record = record\n",
        "\n",
        "    return best_score, best_record\n",
        "\n",
        "# Assuming 'query' and 'db_records' are defined in previous cells in your Colab notebook\n",
        "best_keyword_score, best_matching_record = find_best_match_keyword_search(query, db_records)\n",
        "\n",
        "print(f\"Best Keyword Score: {best_keyword_score}\")\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oak-3k_dkzC3"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blcPOIaHkzC4",
        "outputId": "a9dc44ef-b480-49b6-eb48-b41002bd654a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.126\n"
          ]
        }
      ],
      "source": [
        "# Cosine Similarity\n",
        "score = calculate_cosine_similarity(query, best_matching_record)\n",
        "print(f\"Best Cosine Similarity Score: {score:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OW0l24IkzC5",
        "outputId": "f24affb1-a7d2-49d7-e1ed-47c8a6970ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity:, 0.642\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2zKQhiO0Fcr"
      },
      "source": [
        "## Augmented input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_7ymSxG0Fcs"
      },
      "outputs": [],
      "source": [
        "augmented_input=query+ \": \"+ best_matching_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NTfxzum0PT2",
        "outputId": "42979230-f964-47c2-9156-e37365ed96a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ui8wH4k3_g4"
      },
      "source": [
        "## Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh8BsnUy0Fcs",
        "outputId": "82db2df0-5107-4fea-89ef-ca52ccfd360e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "Certainly! Let's break down the concept of an \"ARAG vector store\" and what it\n",
            "means to have a database or dataset containing vectorized data points.  ### ARAG\n",
            "Vector Store  1. **Definition**:    - An ARAG vector store is essentially a\n",
            "specialized type of database or dataset designed to store and manage vectorized\n",
            "data points. These data points are typically numerical representations of\n",
            "information, often derived from text, images, or other data types through a\n",
            "process called vectorization.  2. **Vectorization**:    - Vectorization is the\n",
            "process of converting data into a numerical format that can be easily processed\n",
            "by machine learning algorithms. For example, in natural language processing\n",
            "(NLP), words or sentences are often transformed into vectors using techniques\n",
            "like word embeddings (e.g., Word2Vec, GloVe) or sentence embeddings (e.g., BERT,\n",
            "Sentence Transformers).  3. **Purpose**:    - The primary purpose of a vector\n",
            "store is to facilitate efficient storage, retrieval, and manipulation of these\n",
            "vectorized data points. This is crucial for tasks such as similarity search,\n",
            "clustering, classification, and other machine learning applications.  4.\n",
            "**Applications**:    - **Similarity Search**: Finding similar items based on\n",
            "their vector representations. For example, in a recommendation system, you might\n",
            "want to find products similar to a user's past purchases.    - **Clustering**:\n",
            "Grouping similar data points together. This is useful in market segmentation,\n",
            "image recognition, and more.    - **Classification**: Assigning labels to data\n",
            "points based on their vector representations. This is common in sentiment\n",
            "analysis, spam detection, etc.  5. **Storage and Retrieval**:    - Vector stores\n",
            "are optimized for handling high-dimensional data and often include specialized\n",
            "indexing techniques to speed up search and retrieval operations. Examples of\n",
            "such techniques include KD-trees, Ball trees, and more advanced methods like\n",
            "Approximate Nearest Neighbors (ANN).  6. **Examples**:    - Some popular vector\n",
            "stores and libraries include FAISS (Facebook AI Similarity Search), Annoy\n",
            "(Approximate Nearest Neighbors Oh Yeah), and Elasticsearch with vector\n",
            "capabilities.  In summary, an ARAG vector store is a powerful tool for managing\n",
            "and utilizing vectorized data, enabling various advanced data processing and\n",
            "machine learning tasks. It plays a crucial role in applications that require\n",
            "understanding and manipulating complex data representations.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJH2__0iTUr1"
      },
      "source": [
        "# 3.Advanced RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awyjcn35jFiy"
      },
      "source": [
        "## 3.1.Vector search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD8_758kkq3h"
      },
      "source": [
        "### Search function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCBbY4qLc8qh"
      },
      "outputs": [],
      "source": [
        "def find_best_match(text_input, records):\n",
        "    best_score = 0\n",
        "    best_record = None\n",
        "    for record in records:\n",
        "        current_score = calculate_cosine_similarity(text_input, record)\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_record = record\n",
        "    return best_score, best_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG1iM-U33OCg"
      },
      "outputs": [],
      "source": [
        "best_similarity_score, best_matching_record = find_best_match(query, db_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLa9NQ4Cm_YQ",
        "outputId": "df567b6a-1b4a-4f6a-a913-60e3edb4883a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A60QoOA3jf9j"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIUh-38knHLI",
        "outputId": "7b8e0ee8-827f-4fa4-c9fe-2fdec7b175f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.126\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQopW_FSjBSr",
        "outputId": "cc6cdfd2-0f3f-4c09-bd04-7c43a3cc8649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity:, 0.642\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, best_matching_record)\n",
        "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51fZC6Oe2G9E"
      },
      "source": [
        "### Augmented input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dcnK7OGx5e6"
      },
      "outputs": [],
      "source": [
        "augmented_input=query+\": \"+best_matching_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3uk-91x049J",
        "outputId": "928f5eda-d894-4830-a9c7-d04d461bb19f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFDF6hbi2LF9"
      },
      "source": [
        "### Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJC-mA5ftxFU",
        "outputId": "c67b9a00-78c2-4beb-b88a-127db37f0859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "Certainly! Let's break down the concept of an \"ARAG vector store\" and what it\n",
            "means to have a database or dataset containing vectorized data points.  ### ARAG\n",
            "Vector Store  1. **Definition**:    - An \"ARAG vector store\" refers to a\n",
            "specialized type of database or dataset designed to store and manage vectorized\n",
            "data points. The term \"ARAG\" might be specific to a particular context or\n",
            "system, but generally, it implies a structured way to handle data in vector\n",
            "form.  2. **Vectorized Data Points**:    - **Vectors**: In the context of data\n",
            "storage and processing, a vector is a mathematical representation of data in the\n",
            "form of an array of numbers. Each number in the array represents a dimension of\n",
            "the data.    - **Vectorization**: This is the process of converting data into a\n",
            "numerical format that can be easily processed by machine learning algorithms.\n",
            "For example, text data can be vectorized using techniques like word embeddings\n",
            "(e.g., Word2Vec, GloVe) or sentence embeddings.    - **Data Points**: These are\n",
            "individual units of data that have been transformed into vectors. Each data\n",
            "point is represented as a vector in the vector store.  3. **Purpose and Use\n",
            "Cases**:    - **Efficient Storage**: Vector stores are optimized for storing\n",
            "large volumes of vectorized data efficiently. This is crucial for applications\n",
            "that require fast retrieval and processing of data.    - **Similarity Search**:\n",
            "One of the primary uses of vector stores is to perform similarity searches. This\n",
            "involves finding vectors that are similar to a given query vector, which is\n",
            "essential in applications like recommendation systems, image retrieval, and\n",
            "natural language processing.    - **Machine Learning**: Vector stores are often\n",
            "used in machine learning workflows where data needs to be quickly accessed and\n",
            "processed for training and inference.  4. **Technical Considerations**:    -\n",
            "**Indexing**: Vector stores often use specialized indexing techniques, such as\n",
            "KD-trees or locality-sensitive hashing, to enable fast similarity searches.    -\n",
            "**Scalability**: They are designed to handle large-scale data, making them\n",
            "suitable for big data applications.    - **Integration**: Vector stores can be\n",
            "integrated with machine learning frameworks and databases to provide seamless\n",
            "data processing capabilities.  In summary, an ARAG vector store is a\n",
            "sophisticated system for managing vectorized data, enabling efficient storage,\n",
            "retrieval, and processing of data in applications that require handling complex,\n",
            "high-dimensional data.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7djpPBpm0M2"
      },
      "source": [
        "## 3.2.Index-based search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyDUhy_1lBfT"
      },
      "source": [
        "### Search Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRarT_fym2XC",
        "outputId": "af09947c-5800-4b97-d357-0a3c2c941b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def setup_vectorizer(records):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(records)\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "def find_best_match(query, vectorizer, tfidf_matrix):\n",
        "    query_tfidf = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_tfidf, tfidf_matrix)\n",
        "    best_index = similarities.argmax()  # Get the index of the highest similarity score\n",
        "    best_score = similarities[0, best_index]\n",
        "    return best_score, best_index\n",
        "\n",
        "vectorizer, tfidf_matrix = setup_vectorizer(db_records)\n",
        "\n",
        "best_similarity_score, best_index = find_best_match(query, vectorizer, tfidf_matrix)\n",
        "best_matching_record = db_records[best_index]\n",
        "\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt3iBtJFj4sa"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoNUQqx5j3r4",
        "outputId": "1a531b09-9e22-457b-a610-9108ed06557c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.407\n",
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cosine Similarity\n",
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg910Mhuj3sO",
        "outputId": "bd77ca3e-0769-42a5-9472-7ffda3961ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity:, 0.642\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubm0DTxKeqR9"
      },
      "source": [
        "Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbokQ2eacHjM",
        "outputId": "3f84b618-eba1-4c54-c89b-fa18df9dd336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ability    access  accuracy  accurate     adapt  additional  advancement  \\\n",
            "0   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "1   0.000000  0.000000  0.000000  0.216364  0.000000    0.000000     0.000000   \n",
            "2   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "3   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "4   0.000000  0.000000  0.000000  0.000000  0.000000    0.236479     0.000000   \n",
            "5   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "6   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "7   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "8   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "9   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "10  0.186734  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "11  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "12  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "13  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "14  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "15  0.000000  0.172624  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "16  0.000000  0.317970  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "17  0.000000  0.000000  0.000000  0.206861  0.000000    0.000000     0.000000   \n",
            "18  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "19  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "20  0.000000  0.000000  0.000000  0.000000  0.275802    0.000000     0.000000   \n",
            "21  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "22  0.000000  0.174772  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "23  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "24  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "25  0.000000  0.000000  0.228743  0.000000  0.000000    0.000000     0.000000   \n",
            "26  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.173327   \n",
            "27  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "\n",
            "      advice  algorithms    allows  ...    vector  vectorized      when  \\\n",
            "0   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "1   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "2   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "3   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "4   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "5   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "6   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "7   0.000000    0.220687  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "8   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "9   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "10  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "11  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.295573   \n",
            "12  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "13  0.000000    0.000000  0.000000  ...  0.200131     0.00000  0.000000   \n",
            "14  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "15  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "16  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "17  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "18  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "19  0.244401    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "20  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "21  0.000000    0.000000  0.291503  ...  0.000000     0.00000  0.000000   \n",
            "22  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "23  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "24  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "25  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "26  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "27  0.000000    0.000000  0.000000  ...  0.307719     0.34589  0.000000   \n",
            "\n",
            "       where     which    while     wide      with    within   without  \n",
            "0   0.000000  0.000000  0.00000  0.00000  0.000000  0.260582  0.000000  \n",
            "1   0.000000  0.000000  0.00000  0.00000  0.160278  0.000000  0.000000  \n",
            "2   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "3   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "4   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "5   0.000000  0.247710  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "6   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "7   0.000000  0.179053  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "8   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "9   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "10  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "11  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "12  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "13  0.000000  0.182517  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "14  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "15  0.189283  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "16  0.000000  0.000000  0.00000  0.00000  0.258278  0.000000  0.000000  \n",
            "17  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "18  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "19  0.217430  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "20  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "21  0.000000  0.000000  0.00000  0.00000  0.192110  0.000000  0.291503  \n",
            "22  0.000000  0.000000  0.00000  0.21541  0.141963  0.000000  0.000000  \n",
            "23  0.000000  0.000000  0.32932  0.00000  0.217033  0.000000  0.000000  \n",
            "24  0.000000  0.000000  0.00000  0.00000  0.134513  0.000000  0.000000  \n",
            "25  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "26  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "27  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "\n",
            "[28 rows x 297 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def setup_vectorizer(records):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(records)\n",
        "\n",
        "    # Convert the TF-IDF matrix to a DataFrame for display purposes\n",
        "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Display the DataFrame\n",
        "    print(tfidf_df)\n",
        "\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "vectorizer, tfidf_matrix = setup_vectorizer(db_records)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dABZ12Bkugtt"
      },
      "source": [
        "### Augmented input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w4wppuA4eNn"
      },
      "outputs": [],
      "source": [
        "augmented_input=query+\": \"+best_matching_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNozI65K4e7u",
        "outputId": "e4a2dec1-65dc-44e1-f80b-2661f7914416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU998zkD4hpD"
      },
      "source": [
        "### Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy9X-l_Iugtt",
        "outputId": "644c0da4-0dca-4582-bb79-5090652976b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "An ARAG vector store, or more generally a vector store, is a specialized type of\n",
            "database or dataset designed to store and manage vectorized data points. Here's\n",
            "a more detailed explanation of what this entails:  1. **Vectorized Data\n",
            "Points**: In the context of machine learning and data science, data is often\n",
            "represented in the form of vectors. A vector is essentially an array of numbers\n",
            "that can represent various types of data, such as text, images, or any other\n",
            "form of structured or unstructured data. These vectors are typically generated\n",
            "through processes like embedding, where complex data is transformed into a\n",
            "numerical format that can be easily processed by algorithms.  2. **Purpose of a\n",
            "Vector Store**: The primary purpose of a vector store is to efficiently store\n",
            "and retrieve these vectorized representations. This is particularly useful in\n",
            "applications such as similarity search, recommendation systems, and clustering,\n",
            "where the goal is to find data points that are similar to a given query vector.\n",
            "3. **Structure and Functionality**: A vector store is optimized for operations\n",
            "that involve high-dimensional vector data. It often includes functionalities\n",
            "such as indexing, which allows for fast retrieval of vectors, and distance\n",
            "metrics, which are used to measure the similarity or dissimilarity between\n",
            "vectors. Common distance metrics include Euclidean distance, cosine similarity,\n",
            "and Manhattan distance.  4. **Applications**: Vector stores are widely used in\n",
            "various fields, including natural language processing (NLP), computer vision,\n",
            "and recommendation systems. For example, in NLP, word embeddings like Word2Vec\n",
            "or BERT generate vector representations of words or sentences, which can then be\n",
            "stored in a vector store for tasks like semantic search or document clustering.\n",
            "5. **Examples of Vector Stores**: There are several tools and platforms designed\n",
            "specifically for managing vector data. Some popular examples include FAISS\n",
            "(Facebook AI Similarity Search), Annoy (Approximate Nearest Neighbors Oh Yeah),\n",
            "and Elasticsearch with its vector search capabilities.  In summary, an ARAG\n",
            "vector store is a crucial component in modern data processing and machine\n",
            "learning workflows, enabling efficient storage, retrieval, and manipulation of\n",
            "vectorized data.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWEvzcDHTX6i"
      },
      "source": [
        "# 4.Modular RAG\n",
        "\n",
        "Modular RAG can combine methods. For example:\n",
        "\n",
        "**keyword search**:Searches through each document to find the one that best matches the keyword(s).\n",
        "\n",
        "**vector search**: Searches through each document and calculates similarity.\n",
        "\n",
        "**indexed search**: Uses a precomputed index (TF-IDF matrix) to compute cosine similarities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv-VqmLf3EQ9"
      },
      "source": [
        "**October 25, 2025 update**\n",
        "\n",
        "`self.documents` is initialized in the fit method to hold the records used for searching and enable the `keyword_search` function to access them without error.\n",
        "\n",
        "**Note on Vector search**\n",
        "\n",
        "In this case, the `def vector_search(self, query):` uses `tfidf_matrix`to increase the vector search performance.\n",
        "\n",
        "The `def vector_search(self, query):` function could use a brute-force method as implemented in `Section 3.1.Vector search` of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18wmqwJd4o62"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class RetrievalComponent:\n",
        "    def __init__(self, method='vector'):\n",
        "        self.method = method\n",
        "        if self.method == 'vector' or self.method == 'indexed':\n",
        "            self.vectorizer = TfidfVectorizer()\n",
        "            self.tfidf_matrix = None\n",
        "\n",
        "    def fit(self, records):\n",
        "      self.documents = records  # Initialize self.documents here\n",
        "      if self.method == 'vector' or self.method == 'indexed':\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(records)\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        if self.method == 'keyword':\n",
        "            return self.keyword_search(query)\n",
        "        elif self.method == 'vector':\n",
        "            return self.vector_search(query)\n",
        "        elif self.method == 'indexed':\n",
        "            return self.indexed_search(query)\n",
        "\n",
        "    def keyword_search(self, query):\n",
        "        best_score = 0\n",
        "        best_record = None\n",
        "        query_keywords = set(query.lower().split())\n",
        "        for index, doc in enumerate(self.documents):\n",
        "            doc_keywords = set(doc.lower().split())\n",
        "            common_keywords = query_keywords.intersection(doc_keywords)\n",
        "            score = len(common_keywords)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_record = self.documents[index]\n",
        "        return best_record\n",
        "\n",
        "    def vector_search(self, query):\n",
        "        query_tfidf = self.vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
        "        best_index = similarities.argmax()\n",
        "        return db_records[best_index]\n",
        "\n",
        "    def indexed_search(self, query):\n",
        "        # Assuming the tfidf_matrix is precomputed and stored\n",
        "        query_tfidf = self.vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
        "        best_index = similarities.argmax()\n",
        "        return db_records[best_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qHm4saJ8cGk"
      },
      "source": [
        "### Modular RAG Strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kvhIOdY8amp",
        "outputId": "0e136233-8027-4294-b552-e5e966e032df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Usage example\n",
        "retrieval = RetrievalComponent(method='vector')  # Choose from 'keyword', 'vector', 'indexed'\n",
        "retrieval.fit(db_records)\n",
        "best_matching_record = retrieval.retrieve(query)\n",
        "\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgxXdqzvkYDk"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COyYme4IkYDx",
        "outputId": "09a2cf28-18c7-469a-fd7e-983175863bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.407\n",
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cosine Similarity\n",
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YRTpIpzkYDx",
        "outputId": "32636fd8-a921-4c98-9c69-3cb22bb27023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity: 0.641582812483307\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(\"Enhanced Similarity:\", similarity_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TaQa7Dc7JwT"
      },
      "source": [
        "### Augmented Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-hKjhIU7Jwg"
      },
      "outputs": [],
      "source": [
        "augmented_input=query+ \" \"+ best_matching_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhSO-fyZ7Jwg",
        "outputId": "7660703c-0626-4762-b665-644a0dc8f34c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "define a rag store A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkyYx_MC7Jwg"
      },
      "source": [
        "### Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V3srRHW7Jwh",
        "outputId": "c8dd4723-1df9-4108-97c1-14e498baf08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "Certainly! Let's break down the concept of a \"vector store\" or \"vector database\"\n",
            "and understand its significance in the context of data storage and retrieval.\n",
            "### What is a Vector Store?  A **vector store** or **vector database** is a\n",
            "specialized type of database or dataset designed to store and manage data in the\n",
            "form of vectors. Vectors are mathematical representations of data points, often\n",
            "used in machine learning and data science to represent features of data in a\n",
            "numerical format.  ### Key Characteristics of a Vector Store:  1. **Vectorized\n",
            "Data Points**:     - The primary feature of a vector store is that it contains\n",
            "data points that have been converted into vectors. These vectors are typically\n",
            "arrays of numbers that represent various attributes or features of the data.  2.\n",
            "**Efficient Similarity Search**:    - Vector stores are optimized for performing\n",
            "similarity searches. This means they can quickly find vectors that are similar\n",
            "to a given query vector. This is particularly useful in applications like\n",
            "recommendation systems, image and text retrieval, and natural language\n",
            "processing.  3. **High-Dimensional Data**:    - Vectors can be high-dimensional,\n",
            "meaning they can have many components. This allows for the representation of\n",
            "complex data structures and relationships.  4. **Scalability**:    - Vector\n",
            "stores are designed to handle large volumes of data efficiently. They can scale\n",
            "to accommodate millions or even billions of vectors, making them suitable for\n",
            "large-scale applications.  5. **Integration with Machine Learning**:    - Vector\n",
            "stores are often used in conjunction with machine learning models. For example,\n",
            "embeddings generated by neural networks can be stored in a vector database for\n",
            "fast retrieval and analysis.  ### Applications of Vector Stores:  1.\n",
            "**Recommendation Systems**:    - Vector stores can be used to store user and\n",
            "item embeddings, enabling the system to recommend items that are similar to\n",
            "those a user has liked in the past.  2. **Image and Video Retrieval**:    - By\n",
            "storing image and video embeddings, vector stores allow for efficient retrieval\n",
            "of similar images or videos based on content.  3. **Natural Language\n",
            "Processing**:    - In NLP, word embeddings or sentence embeddings can be stored\n",
            "in a vector database to facilitate tasks like semantic search or document\n",
            "clustering.  4. **Anomaly Detection**:    - Vector stores can be used to detect\n",
            "anomalies by identifying data points that are significantly different from the\n",
            "rest of the dataset.  ### Conclusion:  A vector store is a powerful tool in the\n",
            "realm of data science and machine learning, enabling efficient storage,\n",
            "retrieval, and analysis of vectorized data. Its ability to handle high-\n",
            "dimensional data and perform fast similarity searches makes it an essential\n",
            "component in various modern applications.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}